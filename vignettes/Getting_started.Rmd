---
title: "Getting started with the artemis package"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Getting_started}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE, echo = FALSE}
knitr::opts_chunk$set(
  eval = FALSE, # for while editing vignette
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, echo = FALSE}
library(artemis)
```

The `artemis` package was created to aid in the design and analysis of
eDNA survey studies by offering a custom suite of models for eDNA
sampling and qPCR data. Typically, data collected from these studies
are modeled using a simple binary response of detection/no
detection. While this approach has been OK, there are several
characteristics of eDNA data which made us feel that
modeling eDNA data could benefit from a different modeling approach:

  1. In eDNA samples, the concentration of eDNA is not directly
     measured. Instead, the amount of eDNA present is represented as a
     function of the number of quantification cycles of qPCR
     (hereafter referred to as the "Cq" value) completed before
     amplification takes place. eDNA concentration ($[eDNA]$) is then
     related to Cq via a standard curve generated in the lab for the
     target species. This standard curve formula typically takes the
     form: $$Cq = log[eDNA] * \beta + \alpha$$. The standard curve is
     specific to the lab reagents and techniques used. **The
     implication of this is that models using Cq values (or a derived
     value such as "postitive detection") as the response result in
     estimates of effect sizes which cannot be directly compared
     between different studies using different standard curves.**
	 
  2. A higher Cq value corresponds to a lower concentration of eDNA in
     a sample. Above a pre-determined threshold, additional
     quantification cycles are not attempted. Therefore,
     "non-detection" is taken to be any sample which requires more
     than the threshold number of cycles to detect. **Not taking this
     data truncation process into account in the model can result in
     increased uncertainty and bias in our estimates of the effect
     sizes.**
  
  3. The potential sources of measurement error in the extraction and
     qPCR processes are difficult to separate and quantify. For
     example, Cq values produced by qPCR become more variable at the
     threshold of detection, i.e. as the number of eDNA molecules
     available for amplification approaches zero.  This source of
     variability in the response is different from that produced by
     error introduced in the pipetting process during extraction, but
     they have the same effect on Cq (namely, increasing variability).
	 
The `artemis` package addresses these issues by directly modeling the
effect of the predictors on the latent (unobserved) variable, eDNA
concentration. It does this by linking eDNA concentration to the 
observed response via the standard curve parameters. The general model is as follows:

$$ Cq_i \sim Normal(\hat{Cq_i}, \sigma_{Cq}) \\
\hat{Cq_i} = \alpha_{std\_curve} + \beta_{std\_curve}* log[eDNA]_i  \\
log[eDNA]_{i} = X_{i} \beta$$

where $\beta$ is a vector of effects on $log[eDNA]$, X is the model
matrix of predictors and
$\alpha_{std\_curve}$ and $\beta_{std\_curve}$ are fixed values
provided by the standard curve.

As detection limits vary with genetic assay, the upper threshold on Cq
in the model is adjustable.  Any values of $\hat{Cq_i}$ which are
greater than the upper limit on $Cq_i$ are recorded as the threshold
value.  For example, a $\hat{Cq_i}$ value of 42 is recorded as 40 when
the upper limit is 40 cycles.
   
   
This model formulation makes several assumptions:
 
  - $log[eDNA]$ is assumed to be uniform within a sample
  
  - $log[eDNA]$ is sampled without error.
  
  - All measurement error is introduced in the extraction/qPCR
    stage. Field sampling is assumed to take place without error.*
	
  - There are no false detections, i.e. the measurement error cannot
    result in a positive detection when eDNA is not present in the
    sample. 


*`*`Future versions of the `artemis` package might allow for measurement
error in both the field collection and qPCR stages.*

Importantly, this formulation produces estimates of the effect sizes
which:


  - are modeled directly on $log[eDNA]$ rather than Cq, *therefore are independent
	of the standard curve and can be compared between studies*.
  
  - account for the data truncation at the upper limit of qPCR
    cycles, *which reduces uncertainty and bias in the estimates.*
	
  - directly model the measurement error on qPCR extraction, *allowing
    quantification of the amount of uncertainty attributable to
    uncertainty in the effect sizes vs. lab procedure.*

In `artemis`, the model is specified using a model formula, similar to
the `lm()` or `lmer()` functions. This model formula is used to
construct the model on $log[eDNA]$.

# A note on included sample data

`artemis` was originally written to analyze aquatic eDNA samples,
therefore the examples and sample data included in the package have
variables that are specific to aquatic eDNA survey data. Specifically,
many of the variables relate to "live car" experiments, where eDNA is
sampled at known distances from a source of eDNA (fish in a net pen in
unidirectional flow, for example). These variables include `volume`
(the the number of mililiters of water that went through the filter in
each sample) and `distance` (the distance in meters from the source of
eDNA).  

The functions in `artemis` generalize to any eDNA survey data with the
following requirements. First, that study must generates Cq values and
second, those Cq values are associated with a standard curve for the
target species.

In the following examples, `tech_rep` refers to technical replicates
extracted from a single eDNA sample; `rep` refers to a single eDNA
sample.

# Simulations

One of the most basic tasks for the `artemis` package is simulating
data. This data is generated using the same data generation process as
the model outlined above. Simulated data is useful for testing
assumptions, designing a study, or doing a post-hoc analysis.

To simulate data, we first must provide a set of levels for each
variable in your survey data.  For example, if the hypothetical
experiment had varying levels of the variables `distance`, `volume`,
`tech_rep`, and `rep`, we would create a list with the variable names
and the associated levels

```{r}
vars = list(Intercept = 1,
            distance = c(0, 15, 50),
            volume = c(25, 50),
            tech_rep = 1:10,
            rep = 1:3,
            Cq = 1)
```

Notice that we provided a level for the intercept, as well as a dummy
variable for the response. The response dummy variable (`Cq = 1`
above) is only used internally to create the model matrix.  By
default, the simulation functions construct a model matrix assuming a
complete block design (i.e. every level of each variable is
represented). 

Next, we must provide a set of effect sizes for each of the variables
we have in the variable levels. For example, if we were only
simulating data using distance and volume, we might specify the effect sizes as:

```{r}
betas = c(intercept = -10.6, distance = -0.05, volume = 0.02)
```

Again, it is important to remember that these are the effect sizes on
$log[eDNA]$, *not* on the Cq values themselves. All the parameters of
the model are on the scale of $log[eDNA]$, including the
intercept. Hence, we specified the intercept to be -10, which
corresponds to exp(-10)$[eDNA]$. (In practice, if the default value
for log[eDNA] is close to 0, some a negative number less than -10 is a
fair assumption for the intercept beta.)

Finally, to simulate data from a fixed-effects model, we use the
`sim_eDNA_lm()` function:

```{r warning = FALSE}
ans = sim_eDNA_lm(Cq ~ distance + volume, 
                  variable_list = vars,
                  betas = c(intercept = -10.6, distance = -0.05, volume = 0.1),
                  sigma_Cq = 1, 
                  std_curve_alpha = 21.2, 
                  std_curve_beta = -1.5)
```

Notice that we must provide the parameters for the conversion formula
between $log[eDNA]$ and Cq values to the simulation function, as well
as the measurement error on Cq (`sigma_Cq`). 

You might have noticed that when we specified the `vars` above, we
included many variables that we did not include in the formula. By
design, all of the functions ignore extra variables in input
variable_list or data (in the case of the modeling functions). This
allows us to create a comprehensive list of variables we might be
interested in, and then only adjust the model formula to change the
simulations.

By default, the `sim_eDNA_*` functions will only simulate one instance
of the hypothetical survey/experiment, but we can easily simulate many
data sets in one go by adjusting the `n_sim` parameter, e.g.

```{r eval = FALSE}
ans2 = sim_eDNA_lm(Cq ~ distance + volume, 
                  vars,
                  betas = c(intercept = -10.6, distance = -0.05, volume = 0.1),
                  sigma_Cq = 1, 
                  std_curve_alpha = 21.2, 
                  std_curve_beta = -1.5,
                  n_sim = 500)
```

If we want to simulate data for an incomplete block design, we can
specify our own variable data.frame, `X`, in which case the variable
levels are ignored and the provided data.frame is used to create a
model.matrix.

The returned object from the `sim_eDNA_*` functions is a list
containing the latent variable `ln_conc`, the equivalent Cq value
before truncation and measurement error `Cq_hat`, and the Cq value
following the truncation and measurement error `Cq_star`. When
multiple simulations are requested, each of these will be stored in a
matrix, with each column representing a single simulated instance.

To simulate for a mixed-effects model, we use the function
`sim_eDNA_lmer()`. Random effects are specified using the syntax of
the `lme4` package, e.g. `(1|random effect)`:

```{r warning = FALSE}
ans3 = sim_eDNA_lmer(Cq ~ distance + volume + (1|rep) + (1|tech_rep),
                     variable_levels = vars,
                     betas = c(intercept = -10.6, distance = -0.05, volume = 0.01),
                     sigma_Cq = 1,
                     sigma_rand = c(0.1, 0.1), #stdev of the random effects
                     std_curve_alpha = 21.2,
                     std_curve_beta = -1.5)

```

When we are simulating data with random effects, we must provide the
standard deviation of the random effects (one for each effect) in
addition to the information for the fixed effects. Random effects are
assumed to be generated from a normal distribution for these
simulations using this standard deviation (`sigma_rand`). When
`n_sims` > 1, different random effects are generated for each
simulation.

The results of a simulation can be inspected via the `summary` and
`plot` methods. These can be helpful when assessing how realistic the
simulated data are, and to test the assumptions behind the model and
the betas used. For example, the results simulated for the
fixed-effects model above can be summarized by calling:

```{r}
summary(ans)
```

The default behavior of `summary()` is to give the empirical marginal
distributions of the simulated data, i.e. the response summarized by
each level of the variables used to simulate the data. *WARNING: these
marginal effects can be misleading in cases where interactions are
used in the formula.* The summary also includes an empirical summary
of the percent of each level which was detected, i.e. had a Cq value
below the threshold.

So in the output above, 95% of the simulated data with distance = 0
was between 27.8 and 31.6.  The p_detect column is the percentage of
each effect that was below the detection threshold.  In this
simulation, the intercept is pretty low and the effects of distance
and volume are small.  100% of all levels resulted in samples below
the detection threshold.

The results of the simulations can be plotted with `plot()`,

```{r fig = TRUE}
plot(ans)
```

Similar to summary, this plots the response (either Cq or $log[eNDA]$
by each level of the variables used to simulate the data. 

## Study design

Simulations are helpful for designing new studies. Given a set of
assumptions about the effect sizes, we can simulate how well we are
able to either detect eDNA or how accurately we can estimate those
effects given a number of replications and variable levels in the design.

For example, suppose we wanted to design a study exploring the effects
of different distances on the detection of eDNA. From previous
studies, we have estimated the effect of distance to be -0.04 decrease
in log(eDNA concentration) per meter distance. If we want to have a
sense of how many replicates we need for this study to have at least
80% power (at least 80% chance to estimate the effect of distance
without including 0 in the CI), we can get a quick estimate of this
using the `est_power_lm()` and a given number of samples, say 5 reps. To
do this, we specify the number of replicates in the variable_list as
`rep = 1:5`, and specify our effect sizes,

```{r warning = FALSE}
dist_power = est_power_lm(Cq ~ 1 + distance,
                          variable_list = list(Cq = 1, distance = c(0,100,300), rep = 1:5),
                          betas = c(intercept = -10.6, distance = -0.04),
                          sigma_Cq = 1, 
                          std_curve_alpha = 21.2, std_curve_beta = -1.5,
                          type = "exclude_zero")

dist_power

```

It appears that 5 samples was not enough in this case. We could
keep trying different number of replicates until we get the number we
would like. However, it is easier to use the function
`est_power_range_lm`, which will automate this process for us. The
call is similar to the above, but instead of specifying the number of
replicates in the `variable_list`, we provide a `rep_range`, which is
`seq(2,20,2)` (every 2 from 2 to 20) by default. Warning, this is
quite CPU intensive, so for this demonstation, we will be lowering the
`rep_range` and the number of iterations for each case,

```{r warning = FALSE}
dist_power_range = est_power_range_lm(Cq ~ 1 + distance,
                                variable_list = list(Cq = 1, distance = c(0,100,300)),
                                betas = c(intercept = -10.6, distance = -0.04),
                                sigma_Cq = 1, 
                                std_curve_alpha = 21.2, std_curve_beta = -1.5,
                                type = "exclude_zero",
                                rep_range = c(5,10), n_sims = 50)

dist_power_range
```

For this study, it looks like we will need greater then 8 replicates
to have our desired 80% power. 

**TODO: Print method: results are ugly to look at?**

# Modeling

The second purpose of the `artemis` package is to fit a model to
collected data. Similar to the simulation functions, the `artemis`
package has two functions which fit a Bayesian latent variable model
to eDNA data; `eDNA_lm()` for fixed effects models and `eDNA_lmer()`
for mixed effects models.

The syntax of these functions is similar to the simulation
functions. We provide a model formula, a data.frame with the observed
data, and then the parameters for standard curve formula to convert
between log(eDNA concentration) and Cq values. For example, to fit a
model to the sample data included in `artemis`, `eDNA_samples`:

```{r warning = FALSE}
model_fit = eDNA_lm(Cq ~ Distance, eDNA_samples,
                    std_curve_alpha = 21.2, std_curve_beta = -1.5)

```

The modeling functions use [Stan](mc-stan.org) to fit the Bayesian
model. Full control of the MCMC algorithm can be accomplished by
passing arguments to `rstan::stan()` in the modeling functions. For
example, 


```{r warning = FALSE}
model_fit = eDNA_lm(Cq ~ Distance, eDNA_samples,
                    std_curve_alpha = 21.2, std_curve_beta = -1.5,
                    iter = 1000)

```

By default, `artemis` suppresses the (often verbose) output from Stan,
but users can (and should) enable it when the model is slow or the
output suggests the MCMC algorithm might not have converged, for
example,

```{r warning = FALSE}
model_fit = eDNA_lm(Cq ~ Distance, eDNA_samples,
                    std_curve_alpha = 21.2, std_curve_beta = -1.5,
                    iter = 100, n_chain = 1,
                    verbose = TRUE)
```

To fit a model with a random effect, use the
`eDNA_lmer()` function and specify the random effects using the syntax
used by `lme4`:

```{r warning = FALSE}
model_fit2 = eDNA_lmer(Cq ~ Distance + Volume + (1|SampleID),
                       eDNA_samples,
                       std_curve_alpha = 21.2, std_curve_beta = -1.5)

```

As with the simulations, the model results can be summarized with
`summary()` and can be plotted with `plot()`,

```{r}
summary(model_fit2)
```

**TODO:** PLOT

## Post-hoc p(detect)

It is common that the purpose of a eDNA sampling study is to inform
the deployment of an automated sampler in the field. For these cases,
we often want to know how likely we are to detect eDNA given the
estimated parameters of the model and a set of conditions. For these
circumstances, we can use the `est_p_detect()` function to see how
well we can detect given effect sizes and conditions,

```{r}
p_detect = est_p_detect(variable_levels = c(Intercept = 1, Distance = 100),
                        betas = c(Intercept = -10.5, Distance = -0.04),
                        Cq_sd = 1, std_curve_alpha = 21.2, std_curve_beta = -1.5,
                        n_rep = 1:12)
print(p_detect)
```
and we can plot this,

```{r fig = TRUE}
plot(p_detect)

```

Alternatively, we can also use a fit model to estimate the p(detect)
for a set of circumstances. Unlike the above, using a fit model allows
us to estimate the probability of detection with the uncertainty in
our effect size estimates taken into account.

```{r}
p_detect2 = est_p_detect(variable_levels = c(Intercept = 1, Distance = 100),
                        model_fit = model_fit, 
                        Cq_sd = 1, std_curve_alpha = 21.2, std_curve_beta = -1.5,
                        n_rep = 1:12)

print(p_detect2)
```

and we can plot the results,

```{r fig = TRUE}
plot(p_detect2)
```

Notice how we get uncertainty intervals when we use a fit model. 

## Predicting outcomes

Once a model is fit, it can be helpful to predict the outcome, either
for the data used to fit the model or new data. For this, `artemis`
provides methods for `predict()` for models fit with `eDNA_lm*()`. 
